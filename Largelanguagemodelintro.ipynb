{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeGaE3fzFRyxPMFbvf7mgK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LILY-182/intro-to-LLM/blob/main/Largelanguagemodelintro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### history of large language models(LLMs)\n",
        "in the recent years, (LLMs) have emerged as transformative tools in the field of natural\n",
        "language processing (NLP). Powered by advanced machine learning techniques, these models have revolutionized the way we interact with and understand textual data. we'll delve\n",
        "into the inner workings of LLMs, explore their capabilities, and discuss their vast potential in various applications, all with a focus on Python\n",
        "\n",
        "##understanding LLMs\n",
        "At the core of LLMs lies the concept of deep learning, a subfield of machine learning that focuses on\n",
        "training neural networks with multiple layers to extract complex patterns from data. In the context of\n",
        "NLP, LLMs are neural network architectures designed to understand and generate human-like text.\n",
        "One of the most prominent LLM architectures is OpenAI's GPT (Generative Pre-trained Transformer)\n",
        "model. Let's take a look at how we can leverage the power of GP\n",
        "\n",
        "## applications of LLMs\n",
        "1. <b>Content Generation:</b> LLMs excel at generating human-like text across various genres, including storytelling, news articles, and technical documentation.\n",
        "2. <b>Language Translation:</b> LLMs can also facilitate language translation tasks by converting text from one\n",
        "language to another\n",
        "3. <b>Sentiment Analysis: </b> LLMs can analyze the sentiment oftextual data, helping businesses gain insights\n",
        "into customer feedback and social media interactions\n",
        "a machine or a computer can understand the context of a text and suggest whether its positive or negative or nuetral\n",
        "\n",
        "##architecture of LLM\n",
        "transformer models - generative  pretrained transformers.\n",
        "llms are built on top of that one"
      ],
      "metadata": {
        "id": "Zrchn-sulvS9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWqo6j7blZxy",
        "outputId": "5baa3fe6-399f-442d-aa9a-a60badb33aa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "#downloading llm libraries\n",
        "!pip install transformers #used to load the pre trained models from hugging face\n",
        "!pip install tokenizers #breakdown a user input into tokens, so that the input can be understood by the model\n",
        "!pip install torch torchvision torchaudio#building block of neural networks built by facebook"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## steps of building LLM\n",
        "1. request for the user prompt\n",
        "we use a concept called prompt engineering that helps users generate the right prompt that can be used by the llm. reserch on prompt engineeering techniques"
      ],
      "metadata": {
        "id": "gWSv2xFmsm52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = str(input(\"Ask anything...\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuYdktL_tvkN",
        "outputId": "9269767b-ca0f-4aac-d5b3-e7d562af0387"
      },
      "execution_count": 9,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ask anything...what is artificial intelligence\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. load the pre trained models from the hugging face community using the transformers library. Depending on the context. e.g text to speech. sentiment analysis, code - completion, text summarization and text generation"
      ],
      "metadata": {
        "id": "AYCcUWjAuNnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')"
      ],
      "metadata": {
        "id": "IZK09tS3u2AP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Tokenization of the prompt. tekenization is the process in nlp where a textual information is broken down into smaller token that can be used with an llm application. this process sometimes is called encoding because it converts texts to numerical formats called tensors"
      ],
      "metadata": {
        "id": "kqWgBKklvg0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.encode(prompt, return_tensors='pt')\n",
        "tokens\n",
        "#with the tokenizer, the user prompt is converted into smaller numerical tokens that we call tensors\n",
        "#this is because and algorithms work better with numbers, rather than texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1X6NoNOwGkY",
        "outputId": "a5b1f88f-8af8-42e3-88f4-bb1975a24bb3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10919,   318, 11666,  4430]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. text generation (decoding) this is the process where we decode output from our model based on the user prompt using a pre trained model"
      ],
      "metadata": {
        "id": "C1fC0eJRxk_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = model.generate(tokens, max_length=1000, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVvfw4ugyDVD",
        "outputId": "4eb478de-525e-44ec-bf52-49bb0b07322a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10919,   318, 11666,  4430,   290,   703,   857,   340,   670, 19427,\n",
              "           198,   198,   464,  3280,   284,   428,  1808,   318,  2829,    13,\n",
              "         35941,  4430,   318,   407,   257,   649,  3721,    13,   632,   468,\n",
              "           587,  1088,   329,   257,   890,   640,    13,   554,  1109,    11,\n",
              "           340,   318,   530,   286,   262,   749,   880,    12,  4002, 10838,\n",
              "           287,   262,  2214,    13,   383,  3381,   366,   600, 32940,     1,\n",
              "           318,  1690,   973,   284,  3522,   284,   597,  2099,   286,  4572,\n",
              "           326,   318,  6007,   286,  9489,  3716,  8861,    13,  2102,    11,\n",
              "           612,   389,   257,  1271,   286,  1180,  3858,   286,  8217,   326,\n",
              "           460,  1620,   777,  8861,    11,   290,   867,   286,   606,   389,\n",
              "           845,  1180,   422,  1692,    12,  2339,  8217,    13,  1114,  1672,\n",
              "            11,   262,  1692,  3632,   318,   881,   517,  3716,   621,   326,\n",
              "           286,   257,  3644,    11,   543,   318,  1521,   340,   468,   284,\n",
              "           307,  1498,   284,  1620,   867,  1180,  8861,   379,  1752,    13,\n",
              "           770,  1724,   326,   340,   460,   307,   845,  2408,   329,  5384,\n",
              "           284,  1833,   644,   318,  1016,   319,   287,   511, 14290,    13,\n",
              "          8447,    11,   356,   761,   284,   892,   546,   703,   356,   460,\n",
              "          2987,   674,  4547,   286,   703,   674, 14290,   670,    13,   775,\n",
              "           460,   466,   428,   416,  4547,   703,   262,  3632,  2499,    11,\n",
              "           416,  2045,   379,   703,   340, 44020,   351,   584,  3354,   286,\n",
              "           674,  1767,    11,   393,   416, 11065,   262,  4645,   290,  2163,\n",
              "           286, 16890,   287,   674,  3632,    13,  2312,   389,   655,   257,\n",
              "          1178,  6096,   286,  1243,   326,   714,   307,  1760,   284,  1037,\n",
              "           514,  1365,  1833,   703,  3632,  5499,   670,   290,   644,   356,\n",
              "           815,   307,  1804,   284,  2987,   606,    13,   628,   198,  2061,\n",
              "           389,   617,   286,   534,  4004,  2842,   284,  2193,   546,  3632,\n",
              "          2163,    30,  1867,   466,   345,   892,   318,   262,  1266,   835,\n",
              "           284,   466,   340,    30,  3914,   514,   760,   287,  3651,  2174,\n",
              "            13, 50256]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#decode the output\n",
        "#this is the process of converting the outputs as tensors(numerical) into textual representation\n",
        "text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "32ZMJGJszKFn",
        "outputId": "1e9ff512-04d9-434d-b000-1a89d860e778"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what is artificial intelligence and how does it work)?\\n\\nThe answer to this question is simple. Artificial intelligence is not a new concept. It has been around for a long time. In fact, it is one of the most well-known concepts in the field. The term \"intelligent\" is often used to refer to any type of machine that is capable of performing complex tasks. However, there are a number of different types of machines that can perform these tasks, and many of them are very different from human-like machines. For example, the human brain is much more complex than that of a computer, which is why it has to be able to perform many different tasks at once. This means that it can be very difficult for humans to understand what is going on in their brains. Therefore, we need to think about how we can improve our understanding of how our brains work. We can do this by understanding how the brain works, by looking at how it interacts with other parts of our body, or by studying the structure and function of neurons in our brain. These are just a few examples of things that could be done to help us better understand how brain functions work and what we should be doing to improve them.\\n\\n\\nWhat are some of your favorite ways to learn about brain function? What do you think is the best way to do it? Let us know in comments below.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}